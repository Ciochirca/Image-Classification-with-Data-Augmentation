{"cells":[{"cell_type":"markdown","metadata":{"id":"3fEa3MGIHl8f"},"source":["#Introduction\r\n","\r\n","Image classification into pictures of cats or pictures of dogs. Following concepts are covered:\r\n","* Building data input pipelines using `tf.keras.preprocessing.image.ImageDataGenerator` class - How can we efficientrly work with data on disk to interface with our model?\r\n","* Overfitting - what is it, how to identify it?\r\n","* Data Augmentation_ and _Dropout_ - Key techniques to fight overfitting in computer vision tasks that we will incorporate into our data pipeline and image classifier model."]},{"cell_type":"markdown","metadata":{"id":"02Uu3wVjJL_M"},"source":["#Importing packages\r\n","* os - to read files and directory structure\r\n","* numpy - for some matrix math outside of TensorFlow\r\n","* matplotlib.pyplot - to plot the graph"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":2488,"status":"ok","timestamp":1612904224177,"user":{"displayName":"Teodor-Avram Ciochirca","photoUrl":"","userId":"00929053556760734917"},"user_tz":-120},"id":"bifsPAAyJq2F"},"outputs":[],"source":["import tensorflow as tf\r\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n","\r\n","import os\r\n","import matplotlib.pyplot as plt\r\n","import numpy as np\r\n","\r\n","import logging\r\n","logger = tf.get_logger()\r\n","logger.setLevel(logging.ERROR)"]},{"cell_type":"markdown","metadata":{"id":"ihsY-AiUNECH"},"source":["#Data Loading\r\n","The dataset we are using is a filtered version of [Dogs vs. Cats](https://www.kaggle.com/c/dogs-vs-cats/data) from Kaggle. We will make use of the class `tf.keras.preprocessing.image.ImageDataGenerator` which will read data from disk. We therefore need to directly download *Cats vs. Dogs* from a URL and unzip it to the Colab filesystem."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"73KOQS6KN_O9","outputId":"ddf37cea-da9f-4079-dd9c-161440f7ece2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n","68608000/68606236 [==============================] - 1s 0us/step\n"]}],"source":["_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\r\n","zip_dir = tf.keras.utils.get_file('cats_and_dogs_filtered.zip', origin=_URL, extract=True)"]},{"cell_type":"markdown","metadata":{"id":"PnAgmN7pPgvX"},"source":["We can list all directories with the following command:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uqOkjqZqPjnW"},"outputs":[],"source":["zip_dir_base = os.path.dirname(zip_dir)\r\n","!find $zip_dir_base -type d -print"]},{"cell_type":"markdown","metadata":{"id":"SqAfSHsnP6ly"},"source":["We can assign variables with the proper file path for the training and validation sets."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dXVQtgdJP-tW"},"outputs":[],"source":["base_dir = os.path.join(os.path.dirname(zip_dir), 'cats_and_dogs_filtered')\r\n","train_dir = os.path.join(base_dir, 'train')\r\n","validation_dir = os.path.join(base_dir, 'validation')\r\n","\r\n","train_cats_dir = os.path.join(train_dir, 'cats') #dir with training cat pictures\r\n","train_dogs_dir = os.path.join(train_dir, 'dogs') #dir with our training dog pictures\r\n","validation_cats_dir = os.path.join(validation_dir, 'cats') #dir with our validation dog pictures\r\n","validation_dogs_dir = os.path.join(validation_dir, 'dogs')  # directory with our validation dog pictures"]},{"cell_type":"markdown","metadata":{"id":"F4e1SVkjROfx"},"source":["## Understanding our data\r\n","Let's look at how many cats and dogs images we have in our training and validation directory."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AXikBF9_RgIs"},"outputs":[],"source":["num_cats_tr = len(os.listdir(train_cats_dir))\r\n","num_dogs_tr = len(os.listdir(train_dogs_dir))\r\n","\r\n","num_cats_val = len(os.listdir(validation_cats_dir))\r\n","num_dogs_val = len(os.listdir(validation_dogs_dir))\r\n","\r\n","total_train = num_cats_tr + num_dogs_tr\r\n","total_val = num_cats_val + num_dogs_val"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HkECba7_SbYD"},"outputs":[],"source":["print('Total training cat images: ', num_cats_tr)\r\n","print('Total training dog images: ', num_dogs_tr)\r\n","\r\n","print('Total validation cat iamges ', num_cats_val)\r\n","print('Total validation dog images ', num_dogs_val)\r\n","print('****')\r\n","print('Total training images ', total_train)\r\n","print('Total validation images: ', total_val)"]},{"cell_type":"markdown","metadata":{"id":"D3Xw82ajTFDF"},"source":["#Setting Model Parameters\r\n","For convenience we'll set up variables that will be used later while pre-processing our dataset and training our network."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vFk-bPEITOAj"},"outputs":[],"source":["BATCH_SIZE = 100 #Number of training examples to process before updating our models variables\r\n","IMG_SHAPE = 150 #Our training data consists of images with width 150 pixels and height of 150 pixels"]},{"cell_type":"markdown","metadata":{"id":"5WSxpHKl7WXW"},"source":["#Data Augmentation\r\n","\r\n","Overfitting often occurs when we have a small number of training examples. One way to fix this problem is to augment our dataset so that it has sufficient number and variety of training examples. Data augmentation takes the approach of generating more training data from existing training samples, by augmenting the samples through random transformations that yield believable-looking images. The goal is at the training time, your model will never see the exact same picture twice. This exposes the model to more aspects of the data allowing it to generalize better.\r\n","\r\n","In **tf.keras** we can implement this using the same **ImageDataGenerator** class. We can simply pass different transformations we would want to our dataset as a form of arguments and it will take care of applying it to the dataset during our training process.\r\n","\r\n","To start off we can define a function that can display an image, so we can see the type of augmentation that has been performed. Then, we'll look at specific augmentations that we'll use during training."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7aVwWNEb9AAH"},"outputs":[],"source":["# This function will plot images in the form of a grid with 1 row and 5 columns where images are placed in each column.\r\n","def plotImages(images_arr):\r\n","    fig, axes = plt.subplots(1, 5, figsize=(20,20))\r\n","    axes = axes.flatten()\r\n","    for img, ax in zip(images_arr, axes):\r\n","        ax.imshow(img)\r\n","    plt.tight_layout()\r\n","    plt.show()"]},{"cell_type":"markdown","metadata":{"id":"c5h_G9yA9IAm"},"source":["##Flipping the images horizontally\r\n","\r\n","We can begin by randomly applying horizontal flip augmentation to our dataset and seeing how individual images will look after the transformation. This is achieved by passying `horizontal_flip=True` as an argument to the `ImageDataGenerator` class."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lLgJAeSP9dio"},"outputs":[],"source":["image_gen = ImageDataGenerator(rescale=1./255, horizontal_flip=True)\r\n","\r\n","train_data_gen = image_gen.flow_from_directory(batch_size=BATCH_SIZE,\r\n","                                               directory=train_dir,\r\n","                                               shuffle=True,\r\n","                                               target_size=(IMG_SHAPE,IMG_SHAPE))"]},{"cell_type":"markdown","metadata":{"id":"n2kbzfz_9rR2"},"source":["To see the transformation in action, let's take one sample image from our training set and repeat it five times. The augmentation will be randomly applied (or not) to each repetition."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U-xoJI2E9sJM"},"outputs":[],"source":["augmented_images = [train_data_gen[0][0][0] for i in range(5)]\r\n","plotImages(augmented_images)"]},{"cell_type":"markdown","metadata":{"id":"hLuoO7VA9xug"},"source":["##Rotating the image\r\n","\r\n","The rotation augmentation will randomly rotate the image up to a specified number of degrees. Here, we'll set it to 45."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CxpdXFIi96wM"},"outputs":[],"source":["image_gen = ImageDataGenerator(rescale=1./255, rotation_range=45)\r\n","\r\n","train_data_gen = image_gen.flow_from_directory(batch_size=BATCH_SIZE,\r\n","                                               directory=train_dir,\r\n","                                               shuffle=True,\r\n","                                               target_size=(IMG_SHAPE, IMG_SHAPE))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7BotjMvc99ed"},"outputs":[],"source":["augmented_images = [train_data_gen[0][0][0] for i in range(5)]\r\n","plotImages(augmented_images)"]},{"cell_type":"markdown","metadata":{"id":"viXI7ELd-CtD"},"source":["##Applying Zoom\r\n","\r\n","We can also apply Zoom augmentation to our dataset, zooming images up to 50% randomly."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xaZp7RPZ-JKh"},"outputs":[],"source":["image_gen = ImageDataGenerator(rescale=1./255, zoom_range=0.5)\r\n","\r\n","train_data_gen = image_gen.flow_from_directory(batch_size=BATCH_SIZE,\r\n","                                               directory=train_dir,\r\n","                                               shuffle=True,\r\n","                                               target_size=(IMG_SHAPE, IMG_SHAPE))\r\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1-hZEERh-Oot"},"outputs":[],"source":["augmented_images = [train_data_gen[0][0][0] for i in range(5)]\r\n","plotImages(augmented_images)"]},{"cell_type":"markdown","metadata":{"id":"Gq1O_4Vo-U4s"},"source":["#Putting it all together\r\n","\r\n","We can apply all these augmentations and even others, with just one line of code, by passing the augmentations as arguments with proper values."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"q3LJz-5Y-mFr"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 2000 images belonging to 2 classes.\n"]}],"source":["image_gen_train = ImageDataGenerator(\r\n","    rescale=1./255,\r\n","    rotation_range=45,\r\n","    width_shift_range=0.2,\r\n","    height_shift_range=0.2,\r\n","    shear_range=0.2,\r\n","    zoom_range=0.2,\r\n","    horizontal_flip=True,\r\n","    fill_mode='nearest')\r\n","\r\n","train_data_gen = image_gen_train.flow_from_directory(\r\n","    batch_size=BATCH_SIZE,\r\n","    directory=train_dir,\r\n","    shuffle=True,\r\n","    target_size=(IMG_SHAPE,IMG_SHAPE),\r\n","    class_mode='binary'\r\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aP2GD_43Amvp"},"outputs":[],"source":["augmented_images = [train_data_gen[0][0][0] for i in range(5)]\r\n","plotImages(augmented_images)"]},{"cell_type":"markdown","metadata":{"id":"SwFrTW0RA5yf"},"source":["##Creating Validation Data Generator\r\n","\r\n","Generally, we only apply data augmentation to our training examples, since the original images should be representative of what our model needs to manage. So, in this case we are only rescaling our validation iamges and converting them into batches using `ImageDataGenerator`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5JX8W3RXBQtE"},"outputs":[],"source":["image_gen_val = ImageDataGenerator(rescale=1./255)\r\n","\r\n","val_data_gen = image_gen_val.flow_from_directory(batch_size=BATCH_SIZE,\r\n","                                                 directory=validation_dir,\r\n","                                                 target_size=(IMG_SHAPE, IMG_SHAPE),\r\n","                                                 class_mode='binary')"]},{"cell_type":"markdown","metadata":{"id":"xY5y_b_dBUzN"},"source":["#Model Creation"]},{"cell_type":"markdown","metadata":{"id":"zjWqmPdGBcQc"},"source":["##Define the model\r\n","The model consists of four convolution blocks with a max pool layer in each of them. Before the final Dense layers, we're also applying a Dropout probability of 0.5. It means that 50% of the values coming into the Dropout layer will be set to zero, helping to prevent overfitting.\r\n","Then we have a fully connected layer with 512 units, with a `relu` activation function. The model will output class probabilities for two classes, dogs and cats, using `softmax`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mMQx2HW1CFCd"},"outputs":[],"source":["model = tf.keras.models.Sequential([\r\n","    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\r\n","    tf.keras.layers.MaxPooling2D(2, 2),\r\n","\r\n","    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\r\n","    tf.keras.layers.MaxPooling2D(2,2),\r\n","\r\n","    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\r\n","    tf.keras.layers.MaxPooling2D(2,2),\r\n","\r\n","    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\r\n","    tf.keras.layers.MaxPooling2D(2,2),\r\n","\r\n","    tf.keras.layers.Dropout(0.5),\r\n","    tf.keras.layers.Flatten(),\r\n","    tf.keras.layers.Dense(512, activation='relu'),\r\n","    tf.keras.layers.Dense(2, activation='softmax')\r\n","])"]},{"cell_type":"markdown","metadata":{"id":"rOVAKBwCCIi0"},"source":["##Compiling the model\r\n","\r\n","We use `adam` optimizer and since we use `softmax` we'll use `sparse_categorical_crossentropy` as the loss function. We also want to look at training and validation accuracy on each epoch so we are passing the metric argumet."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UqDBvlTGCm7r"},"outputs":[],"source":["model.compile(optimizer='adam',\r\n","              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\r\n","              metrics=['accuracy'])"]},{"cell_type":"markdown","metadata":{"id":"CijFryzbCvS7"},"source":["##Model Summary"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jtZ4rtjHCyjH"},"outputs":[],"source":["model.summary()"]},{"cell_type":"markdown","metadata":{"id":"tiaJ1RN6C2iG"},"source":["##Train the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WPHCO0lZC5CG"},"outputs":[],"source":["EPOCHS=100\r\n","history = model.fit_generator(\r\n","    train_data_gen,\r\n","    steps_per_epoch=int(np.ceil(total_train / float(BATCH_SIZE))),\r\n","    epochs=EPOCHS,\r\n","    validation_data=val_data_gen,\r\n","    validation_steps=int(np.ceil(total_val / float(BATCH_SIZE)))\r\n",")"]},{"cell_type":"markdown","metadata":{"id":"_KdP-H4WDGWc"},"source":["#Visualizing results of the training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bJR2bmx8DKEo"},"outputs":[],"source":["acc = history.history['accuracy']\r\n","val_acc = history.history['val_accuracy']\r\n","\r\n","loss = history.history['loss']\r\n","val_loss = history.history['val_loss']\r\n","\r\n","epochs_range = range(EPOCHS)\r\n","\r\n","plt.figure(figsize=(8, 8))\r\n","plt.subplot(1, 2, 1)\r\n","plt.plot(epochs_range, acc, label='Training Accuracy')\r\n","plt.plot(epochs_range, val_acc, label='Validation Accuracy')\r\n","plt.legend(loc='lower right')\r\n","plt.title('Training and Validation Accuracy')\r\n","\r\n","plt.subplot(1, 2, 2)\r\n","plt.plot(epochs_range, loss, label='Training Loss')\r\n","plt.plot(epochs_range, val_loss, label='Validation Loss')\r\n","plt.legend(loc='upper right')\r\n","plt.title('Training and Validation Loss')\r\n","plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPJ2HrAaUDss4CKOPIr9coW","name":"Dogs vs. Cats Img Classification With Image Augmentation.ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}